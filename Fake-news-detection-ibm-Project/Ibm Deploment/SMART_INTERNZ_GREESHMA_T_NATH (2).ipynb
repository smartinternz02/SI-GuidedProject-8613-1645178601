{"cells": [{"metadata": {}, "cell_type": "code", "source": "\nimport os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\nclient_9c139c80c2e445f2a9e7ff6e0d231509 = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='TiQkRbufpg1NcXdnyqoxdGV6HtnXb8AWCevCqiqC46AO',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.private.eu.cloud-object-storage.appdomain.cloud')\n\nbody = client_9c139c80c2e445f2a9e7ff6e0d231509.get_object(Bucket='fakenewsanalysisinsocialmediausin-donotdelete-pr-1sxatodmi6xo0k',Key='news.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndf = pd.read_csv(body)\ndf.head()\n", "execution_count": 1, "outputs": [{"output_type": "execute_result", "execution_count": 1, "data": {"text/plain": "   Unnamed: 0                                              title  \\\n0        8476                       You Can Smell Hillary\u2019s Fear   \n1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n2        3608        Kerry to go to Paris in gesture of sympathy   \n3       10142  Bernie supporters on Twitter erupt in anger ag...   \n4         875   The Battle of New York: Why This Primary Matters   \n\n                                                text label  \n0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n3  \u2014 Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n4  It's primary day in New York and front-runners...  REAL  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>title</th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8476</td>\n      <td>You Can Smell Hillary\u2019s Fear</td>\n      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n      <td>FAKE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10294</td>\n      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n      <td>FAKE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3608</td>\n      <td>Kerry to go to Paris in gesture of sympathy</td>\n      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n      <td>REAL</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10142</td>\n      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n      <td>\u2014 Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n      <td>FAKE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>875</td>\n      <td>The Battle of New York: Why This Primary Matters</td>\n      <td>It's primary day in New York and front-runners...</td>\n      <td>REAL</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "#df = pd.read_csv(r'C:\\Users\\grees\\Desktop\\SMartinternz\\IBM_PROJECT\\Fake-news-detection-new-main\\Dataset\\news.csv')\n#df.head()", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Create a series to store the labels: y\n# y = df.label\n\n#cleaned file containing the text and label\nX = df['text']  # independent variable\ny = df['label'] #dependent variable\n", "execution_count": 3, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Create training set and test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.33, random_state=53)\n", "execution_count": 4, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Initialize a CountVectorizer object: count_vectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\ncount_vectorizer = CountVectorizer(stop_words='english')\n\n# Transform the training data using only the 'text' column values: count_train\ncount_train = count_vectorizer.fit_transform(X_train)\n\n# Transform the test data using only the 'text' column values: count_test\ncount_test = count_vectorizer.transform(X_test)\n\n# Print the first 10 features of the count_vectorizer\nprint(count_vectorizer.get_feature_names()[:10])\n", "execution_count": 5, "outputs": [{"output_type": "stream", "text": "['00', '000', '0000', '00000031', '000035', '00006', '0001', '0001pt', '000ft', '000km']\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.feature_extraction.text import TfidfVectorizer\n# Initialize a TfidfVectorizer object: tfidf_vectorizer\ntfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n\n# Transform the training data: tfidf_train\ntfidf_train = tfidf_vectorizer.fit_transform(X_train)\n\n# transform the test data: tfidf_test\ntfidf_test = tfidf_vectorizer.transform(X_test)\n\n# Print the first 10 features\nprint(tfidf_vectorizer.get_feature_names()[:10])\n\n# Print the first 5 vectors of the tfidf training data\nprint(tfidf_train.A[:5])\n", "execution_count": 6, "outputs": [{"output_type": "stream", "text": "['00', '000', '0000', '00000031', '000035', '00006', '0001', '0001pt', '000ft', '000km']\n[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "count_df = pd.DataFrame(count_train.A, columns=count_vectorizer.get_feature_names())\n\n# Create the TfidfVectorizer DataFrame: tfidf_df\ntfidf_df = pd.DataFrame(tfidf_train.A, columns=tfidf_vectorizer.get_feature_names())\n\n# Print the head of count_df\nprint(count_df.head())\n\n# Print the head of tfidf_df\nprint(tfidf_df.head())\n", "execution_count": 7, "outputs": [{"output_type": "stream", "text": "   00  000  0000  00000031  000035  00006  0001  0001pt  000ft  000km  ...  \\\n0   0    0     0         0       0      0     0       0      0      0  ...   \n1   0    0     0         0       0      0     0       0      0      0  ...   \n2   0    0     0         0       0      0     0       0      0      0  ...   \n3   0    0     0         0       0      0     0       0      0      0  ...   \n4   0    0     0         0       0      0     0       0      0      0  ...   \n\n   \u062d\u0644\u0628  \u0639\u0631\u0628\u064a  \u0639\u0646  \u0644\u0645  \u0645\u0627  \u0645\u062d\u0627\u0648\u0644\u0627\u062a  \u0645\u0646  \u0647\u0630\u0627  \u0648\u0627\u0644\u0645\u0631\u0636\u0649  \u0e22\u0e07ade  \n0    0     0   0   0   0        0   0    0        0      0  \n1    0     0   0   0   0        0   0    0        0      0  \n2    0     0   0   0   0        0   0    0        0      0  \n3    0     0   0   0   0        0   0    0        0      0  \n4    0     0   0   0   0        0   0    0        0      0  \n\n[5 rows x 56922 columns]\n    00  000  0000  00000031  000035  00006  0001  0001pt  000ft  000km  ...  \\\n0  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n1  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n2  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n3  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n4  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n\n   \u062d\u0644\u0628  \u0639\u0631\u0628\u064a   \u0639\u0646   \u0644\u0645   \u0645\u0627  \u0645\u062d\u0627\u0648\u0644\u0627\u062a   \u0645\u0646  \u0647\u0630\u0627  \u0648\u0627\u0644\u0645\u0631\u0636\u0649  \u0e22\u0e07ade  \n0  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n1  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n2  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n3  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n4  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n\n[5 rows x 56922 columns]\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# Calculate the difference in columns: difference\ndifference = set(count_df.columns) - set(tfidf_df.columns)\nprint(difference)\n\n# Check whether the DataFrame are equal\nprint(count_df.equals(tfidf_df))\n", "execution_count": 8, "outputs": [{"output_type": "stream", "text": "set()\nFalse\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n# Instantiate a Multinomial Naive Bayes classifier: nb_classifier\nnb_classifier = MultinomialNB()\n\n# Fit the classifier to the training data\nnb_classifier.fit(count_train, y_train)\n\n# Create the predicted tags: pred\npred = nb_classifier.predict(count_test)\n\n# Calculate the accuracy score: score\nscore = accuracy_score(y_test, pred)\nprint(score)", "execution_count": 9, "outputs": [{"output_type": "stream", "text": "0.893352462936394\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "\n# Calculate the confusion matrix: cm\ncm =confusion_matrix(y_test, pred, labels=['FAKE', 'REAL'])\nprint(cm)\n\n", "execution_count": 10, "outputs": [{"output_type": "stream", "text": "[[ 865  143]\n [  80 1003]]\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "#Training and testing the \"fake news\" model with TfidfVectorizer\nnb_classifier = MultinomialNB()\n\n# Fit the classifier to the training data\nnb_classifier.fit(tfidf_train, y_train)\n\n# Create the predicted tags: pred\npred = nb_classifier.predict(tfidf_test)\n\n# Calculate the accuracy score: score\nscore = accuracy_score(y_test, pred)\nprint(score)\n\n# Calculate the confusion matrix: cm\ncm = confusion_matrix(y_test, pred, labels=['FAKE', 'REAL'])\nprint(cm)\n\n", "execution_count": 11, "outputs": [{"output_type": "stream", "text": "0.8565279770444764\n[[ 739  269]\n [  31 1052]]\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "#Improving the model to test a few different alpha levels using the Tfidf vectors,\n# to determine.if there is a better performing combination\nimport numpy as np\nalphas = np.arange(0, 1, 0.1)\n", "execution_count": 12, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Define train_and_predict()\ndef train_and_predict(alpha):\n    # Instantiate the classifier: nb_classifier\n    nb_classifier = MultinomialNB(alpha=alpha)\n    \n    # Fit to the training data\n    nb_classifier.fit(tfidf_train, y_train)\n    \n    # Predict the labels: pred\n    pred = nb_classifier.predict(tfidf_test)\n    \n    # Compute accuracy: score\n    score = accuracy_score(y_test, pred)\n    return score\n", "execution_count": 13, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Iterate over the alphas and print the corresponding score\nfor alpha in alphas:\n    print('Alpha: ', alpha)\n    print('Score: ', train_and_predict(alpha))\n    print()\n", "execution_count": 14, "outputs": [{"output_type": "stream", "text": "Alpha:  0.0\nScore:  0.8813964610234337\n\nAlpha:  0.1\nScore:  0.8976566236250598\n\nAlpha:  0.2\nScore:  0.8938307030129125\n\nAlpha:  0.30000000000000004\nScore:  0.8900047824007652\n\nAlpha:  0.4\nScore:  0.8857006217120995\n\nAlpha:  0.5\nScore:  0.8842659014825442\n\nAlpha:  0.6000000000000001\nScore:  0.874701099952176\n\nAlpha:  0.7000000000000001\n", "name": "stdout"}, {"output_type": "stream", "text": "/opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages/sklearn/naive_bayes.py:511: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n  warnings.warn('alpha too small will result in numeric errors, '\n", "name": "stderr"}, {"output_type": "stream", "text": "Score:  0.8703969392635102\n\nAlpha:  0.8\nScore:  0.8660927785748446\n\nAlpha:  0.9\nScore:  0.8589191774270684\n\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.pipeline import Pipeline\nclass_labels = nb_classifier.classes_\n\n# Extract the features: feature_names\nfeature_names = tfidf_vectorizer.get_feature_names()\n\n# Zip the feature names together with the coefficient array \n# and sort by weights: feat_with_weights\nfeat_with_weights = sorted(zip(nb_classifier.coef_[0], feature_names))\n\n# Print the first class label and the top 20 feat_with_weights entries\nprint(class_labels[0], feat_with_weights[:20])\n\n# Print the second class label and the bottom 20 feat_with_weights entries\nprint(class_labels[1], feat_with_weights[-20:])\n\n#Creating a pipeline that first creates bag of words(after applying stopwords) & then applies Multinomial Naive Bayes model\npipeline = Pipeline([('tfidf', TfidfVectorizer(stop_words='english')),\n                     ('nbmodel', MultinomialNB())])\n\n#Training our data\npipeline.fit(X_train, y_train)\n\n#Predicting the label for the test data\npred = pipeline.predict(X_test)\nprint(confusion_matrix(y_test, pred))\n\n", "execution_count": 15, "outputs": [{"output_type": "stream", "text": "FAKE [(-11.316312804238807, '0000'), (-11.316312804238807, '000035'), (-11.316312804238807, '0001'), (-11.316312804238807, '0001pt'), (-11.316312804238807, '000km'), (-11.316312804238807, '0011'), (-11.316312804238807, '006s'), (-11.316312804238807, '007'), (-11.316312804238807, '007s'), (-11.316312804238807, '008s'), (-11.316312804238807, '0099'), (-11.316312804238807, '00am'), (-11.316312804238807, '00p'), (-11.316312804238807, '00pm'), (-11.316312804238807, '014'), (-11.316312804238807, '015'), (-11.316312804238807, '018'), (-11.316312804238807, '01am'), (-11.316312804238807, '020'), (-11.316312804238807, '023')]\nREAL [(-7.742481952533027, 'states'), (-7.717550034444668, 'rubio'), (-7.703583809227384, 'voters'), (-7.654774992495461, 'house'), (-7.649398936153309, 'republicans'), (-7.6246184189367, 'bush'), (-7.616556675728881, 'percent'), (-7.545789237823644, 'people'), (-7.516447881078008, 'new'), (-7.448027933291952, 'party'), (-7.411148410203476, 'cruz'), (-7.410910239085596, 'state'), (-7.35748985914622, 'republican'), (-7.33649923948987, 'campaign'), (-7.2854057032685775, 'president'), (-7.2166878130917755, 'sanders'), (-7.108263114902301, 'obama'), (-6.724771332488041, 'clinton'), (-6.5653954389926845, 'said'), (-6.328486029596207, 'trump')]\n[[ 739  269]\n [  31 1052]]\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "#Serialising the file\n#pickle.dump(nb_classifier,open('fake_news.pkl','wb'))\n#Serialising the file\nimport pickle\nwith open('model.pkl', 'wb') as handle:\n    pickle.dump(pipeline, handle, protocol=pickle.HIGHEST_PROTOCOL)", "execution_count": 16, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import ibm_watson_machine_learning\nfrom ibm_watson_machine_learning import APIClient\nimport json\nimport numpy as np", "execution_count": 17, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\n# @hidden_cell\n# The following code contains the credentials for a file in your IBM Cloud Object Storage.\n# You might want to remove those credentials before you share your notebook.\n\ncredentials_1 = {\n    #'IAM_SERVICE_ID': 'iam-ServiceId-135863a8-5c3d-4f25-91f0-5e745ce80101',\n    \"apikey\": 'UqKC_K9ox9COEdiL0JxjLV-fr5T0qVXA0FX6b1KmQOD4',\n    \"url\" : \"https://eu-gb.ml.cloud.ibm.com\"\n}\n", "execution_count": 18, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#def guid_from_space_name(client, space_name):\n #   space = client.spaces.list()\n   #return(next(item for item in space['resources'] if item['entity'][\"name\"] == space_name)['metadata']['id'])\nwml_client = APIClient(credentials_1)\nwml_client.spaces.list()", "execution_count": 19, "outputs": [{"output_type": "stream", "text": "Note: 'limit' is not provided. Only first 50 records will be displayed if the number of records exceed 50\n------------------------------------  ---------  ------------------------\nID                                    NAME       CREATED\nc7dfc4be-6712-45d0-bea2-e97aa7eacc5b  Fake_news  2022-03-07T08:31:20.524Z\n------------------------------------  ---------  ------------------------\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "ID=\"c7dfc4be-6712-45d0-bea2-e97aa7eacc5b\"\nwml_client.set.default_space(ID)", "execution_count": 21, "outputs": [{"output_type": "execute_result", "execution_count": 21, "data": {"text/plain": "'SUCCESS'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "MODEL_NAME = \"news\"\nDEPLOYMENT_NAME = \"fake_news\"\nbestmodel= nb_classifier", "execution_count": 25, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "software_spec_uid= wml_client.software_specifications.get_id_by_name('default_py3.8')\n\nmodel_props ={\n    wml_client.repository.ModelMetaNames.NAME:MODEL_NAME,\n    wml_client.repository.ModelMetaNames.TYPE:'scikit-learn_0.23',\n    wml_client.repository.ModelMetaNames.SOFTWARE_SPEC_UID:software_spec_uid\n}\n", "execution_count": 30, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "y_test", "execution_count": 31, "outputs": [{"output_type": "execute_result", "execution_count": 31, "data": {"text/plain": "4221    REAL\n1685    FAKE\n3348    REAL\n2633    REAL\n975     REAL\n        ... \n3888    REAL\n2015    FAKE\n5860    REAL\n3071    FAKE\n4284    REAL\nName: label, Length: 2091, dtype: object"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "\nmodel_details = wml_client.repository.store_model(\nmodel = bestmodel,\nmeta_props = model_props,\n#training_data = X_train,\ntraining_target =y_test\n)", "execution_count": 32, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#set meta\ndeployment_props= {\n    wml_client.deployments.ConfigurationMetaNames.NAME:DEPLOYMENT_NAME,\n    wml_client.deployments.ConfigurationMetaNames.ONLINE:{}\n}\n", "execution_count": 33, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "software_spec_uid", "execution_count": 35, "outputs": [{"output_type": "execute_result", "execution_count": 35, "data": {"text/plain": "'ab9e1b80-f2ce-592c-a7d2-4f2344f77194'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "model_uid = wml_client.repository.get_model_id(model_details)", "execution_count": 36, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "model_uid", "execution_count": 37, "outputs": [{"output_type": "execute_result", "execution_count": 37, "data": {"text/plain": "'829360e8-6846-489f-8fef-473ff4142e50'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "#set meta\ndeployment_props= {\n    wml_client.deployments.ConfigurationMetaNames.NAME:DEPLOYMENT_NAME,\n    wml_client.deployments.ConfigurationMetaNames.ONLINE:{}\n}", "execution_count": 38, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "deployment = wml_client.deployments.create(artifact_uid=model_uid,meta_props=deployment_props)", "execution_count": 39, "outputs": [{"output_type": "stream", "text": "\n\n#######################################################################################\n\nSynchronous deployment creation for uid: '829360e8-6846-489f-8fef-473ff4142e50' started\n\n#######################################################################################\n\n\ninitializing\nNote: online_url is deprecated and will be removed in a future release. Use serving_urls instead.\n\nready\n\n\n------------------------------------------------------------------------------------------------\nSuccessfully finished deployment creation, deployment_uid='2645d777-d20d-442e-bdd4-a51ac7783587'\n------------------------------------------------------------------------------------------------\n\n\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "deployment_uid =wml_client.deployments.get_uid(deployment)\ndeployment_uid", "execution_count": 40, "outputs": [{"output_type": "execute_result", "execution_count": 40, "data": {"text/plain": "'2645d777-d20d-442e-bdd4-a51ac7783587'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "payload = {\"input_data\":\n           [\n               {\"fields\":X_test.tolist(), \"values\":X_test.tolist()}\n           ]\n          }", "execution_count": 42, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#result = wml_client.deployments.score(deployment_uid, payload);result", "execution_count": 44, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import sklearn\nsklearn.__version__", "execution_count": 46, "outputs": [{"output_type": "execute_result", "execution_count": 46, "data": {"text/plain": "'0.23.2'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.8", "language": "python"}, "language_info": {"name": "python", "version": "3.8.12", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 2}